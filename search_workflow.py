import os

try:
    from langchain.retrievers import EnsembleRetriever
except ImportError:
    from langchain_classic.retrievers import EnsembleRetriever
from langchain_community.llms import Ollama
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ----------------------
# 1. æ„é€ ä¸€æ‰¹â€œæ–‡æ¡£â€
# ----------------------
docs = [
    "ç”¨æˆ·ä¸‹å•æµç¨‹ï¼šController â†’ OrderService â†’ OrderManager â†’ OrderDao â†’ DB",
    "OOM é€šå¸¸æ˜¯ batch size å¤ªå¤§ã€æ¨¡å‹åŠ è½½å¤ªå¤šã€å†…å­˜æ³„æ¼å¯¼è‡´",
    "Java è™šæ‹Ÿæœºæ ˆæº¢å‡ºä¸€èˆ¬æ˜¯é€’å½’æ·±åº¦å¤ªæ·±æˆ–å¾ªç¯è°ƒç”¨",
    "AI Search åŒ…å«ï¼šæ„å›¾ç†è§£ã€å¬å›ã€ç²¾æ’ã€ç”Ÿæˆ",
    "RLHF æ˜¯ç”¨å¼ºåŒ–å­¦ä¹ è®©æ¨¡å‹æ›´ç¬¦åˆäººç±»æ„å›¾",
    "è®°å¿†ç³»ç»Ÿæ˜¯å› ä¸º LLM ä¸Šä¸‹æ–‡ä¸å¤Ÿæ‰å‡ºç°çš„è¡¥ä¸æ–¹æ¡ˆ",
]

# ----------------------
# 2. å‘é‡åº“æŒä¹…åŒ–é€»è¾‘
# ----------------------
DB_PATH = "faiss_index_v2"
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")

def get_vector_db_and_splits():
    splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    splits = splitter.create_documents(docs)

    if os.path.exists(DB_PATH):
        db = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
    else:
        db = FAISS.from_documents(splits, embeddings)
        db.save_local(DB_PATH)
    return db, splits

db, splits = get_vector_db_and_splits()

# ----------------------
# 3. æ··åˆæ£€ç´¢å™¨ (Hybrid Search)
# ----------------------
bm25_retriever = BM25Retriever.from_documents(splits)
bm25_retriever.k = 4
faiss_retriever = db.as_retriever(search_kwargs={"k": 4})
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, faiss_retriever],
    weights=[0.5, 0.5]
)

# ----------------------
# 4. ç»†ç²’åº¦æ­¥éª¤å®šä¹‰
# ----------------------
llm = Ollama(model="gemma2:2b")

# Step 1: æ„å›¾è¯†åˆ«
def get_intent(query):
    prompt = PromptTemplate.from_template("åˆ†æç”¨æˆ·é—®é¢˜ï¼Œè¾“å‡ºå”¯ä¸€æ„å›¾ï¼ˆcode_debug, architecture, tech_concept, unknownï¼‰ã€‚é—®é¢˜ï¼š{query}\næ„å›¾ï¼š")
    return llm.invoke(prompt.format(query=query)).strip()

# Step 2: å…³é”®è¯æå– (ç”¨äºå¢å¼ºæ£€ç´¢)
def get_keywords(query):
    prompt = PromptTemplate.from_template("ä»ç”¨æˆ·é—®é¢˜ä¸­æå– 2-3 ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼Œç”¨é€—å·éš”å¼€ã€‚é—®é¢˜ï¼š{query}\nå…³é”®è¯ï¼š")
    keywords = llm.invoke(prompt.format(query=query)).strip()
    print(f"ğŸ”‘ æå–å…³é”®è¯ï¼š{keywords}")
    return keywords

# Step 3: ç»“æœæ ¡éªŒ (è´¨æ£€å‘˜)
def verify_answer(query, context, answer):
    prompt = PromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è´¨æ£€å‘˜ã€‚è¯·åˆ¤æ–­ç»™å‡ºçš„å›ç­”æ˜¯å¦å®Œå…¨åŸºäºå‚è€ƒä¿¡æ¯ã€‚
    å¦‚æœå›ç­”ä¸­åŒ…å«å‚è€ƒä¿¡æ¯é‡Œæ²¡æœ‰çš„å†…å®¹ï¼Œè¯·è¾“å‡º 'FAIL' å¹¶è¯´æ˜åŸå› ã€‚
    å¦‚æœå›ç­”æ­£ç¡®ï¼Œè¯·è¾“å‡º 'PASS'ã€‚

    å‚è€ƒä¿¡æ¯ï¼š{context}
    ç”¨æˆ·é—®é¢˜ï¼š{query}
    ç»™å‡ºå›ç­”ï¼š{answer}

    åˆ¤æ–­ç»“æœï¼š""")
    verification = llm.invoke(prompt.format(query=query, context=context, answer=answer)).strip()
    print(f"âœ… è´¨æ£€ç»“æœï¼š{verification}")
    return "PASS" in verification.upper()

# ----------------------
# 5. AI Searchï¼šAgentic Workflow (å·¥ä½œæµæ¨¡å¼)
# ----------------------
def ai_search_workflow(query):
    print(f"\nğŸš€ å¼€å§‹å¤„ç†é—®é¢˜ï¼š{query}")

    # 1. æ„å›¾è¯†åˆ«
    intent = get_intent(query)
    print(f"ğŸ¤– è¯†åˆ«æ„å›¾ï¼š{intent}")

    # 2. å…³é”®è¯æå–å¹¶æ£€ç´¢
    keywords = get_keywords(query)
    # ä½¿ç”¨å…³é”®è¯è¿›è¡Œæ£€ç´¢ï¼Œé€šå¸¸æ¯”åŸå§‹é•¿å¥æ›´å‡†
    retrieved_docs = ensemble_retriever.invoke(keywords)
    context = "\n".join([d.page_content for d in retrieved_docs[:2]])
    print(f"ğŸ” æ£€ç´¢åˆ° {len(retrieved_docs)} æ¡ç›¸å…³ä¿¡æ¯")

    # 3. ç”Ÿæˆåˆæ­¥å›ç­”
    answer_prompt = PromptTemplate.from_template("ç”¨æˆ·æ„å›¾ï¼š{intent}\nå‚è€ƒä¿¡æ¯ï¼š\n{context}\n\né—®é¢˜ï¼š{query}\nè¯·ç®€æ´å›ç­”ã€‚")
    initial_answer = llm.invoke(answer_prompt.format(intent=intent, context=context, query=query))

    # 4. ç»“æœæ ¡éªŒ
    is_valid = verify_answer(query, context, initial_answer)

    if is_valid:
        return initial_answer
    else:
        return f"âš ï¸ è­¦å‘Šï¼šæ¨¡å‹ç”Ÿæˆå¯èƒ½å­˜åœ¨å¹»è§‰ï¼Œè¯·è°¨æ…å‚è€ƒã€‚\nåˆæ­¥å›ç­”ï¼š{initial_answer}"

if __name__ == "__main__":
    q = "OOM æ€ä¹ˆäº§ç”Ÿçš„ï¼Ÿ"
    print("="*80)
    final_res = ai_search_workflow(q)
    print(f"\nğŸ æœ€ç»ˆå›ç­”ï¼š\n{final_res}")
    print("="*80)
